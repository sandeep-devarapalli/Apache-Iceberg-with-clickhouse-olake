# Docker Compose file for ClickHouse + MySQL + OLake + Iceberg Demo

services:
  # MySQL 8.0 with CDC enabled
  mysql:
    image: mysql:8.0
    container_name: mysql-server
    environment:
      MYSQL_ROOT_PASSWORD: root_password
      MYSQL_DATABASE: demo_db
      MYSQL_USER: demo_user
      MYSQL_PASSWORD: demo_password
    command: >
      --log-bin=mysql-bin --server-id=1 --binlog-format=ROW --gtid-mode=ON --enforce-gtid-consistency=ON --log-slave-updates=ON --binlog-row-image=FULL
    ports:
      - "3307:3306"
    volumes:
      - ./mysql-init:/docker-entrypoint-initdb.d
      - mysql-data:/var/lib/mysql
    networks:
      - clickhouse_lakehouse-net
    healthcheck:
      test: [ "CMD", "mysqladmin", "ping", "-h", "localhost" ]
      timeout: 20s
      retries: 10

  # MinIO S3 Storage for Iceberg
  minio:
    image: minio/minio:latest
    container_name: minio-server
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    command: server /data --console-address ":9091"
    ports:
      - "9090:9000"
      - "9091:9091"
    volumes:
      - minio-data:/data
    networks:
      - clickhouse_lakehouse-net
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3

  # Iceberg REST Catalog
  iceberg-rest:
    image: tabulario/iceberg-rest:0.6.0
    container_name: iceberg-rest
    ports:
      - "8181:8181"
    environment:
      AWS_REGION: us-east-1
      CATALOG_WAREHOUSE: s3://iceberg-warehouse/
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin123
      CATALOG_S3_PATH_STYLE_ACCESS: true
    depends_on:
      minio:
        condition: service_healthy
    networks:
      - clickhouse_lakehouse-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8181/v1/config"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MinIO Client for bucket initialization and management
  minio-client:
    image: minio/mc:latest
    container_name: minio-client
    depends_on:
      minio:
        condition: service_healthy
    volumes:
      - ./scripts:/scripts
    networks:
      - clickhouse_lakehouse-net
    entrypoint: >
      /bin/sh -c " sleep 10; /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin123; /usr/bin/mc mb myminio/iceberg-warehouse --ignore-existing; /usr/bin/mc mb myminio/olake-data --ignore-existing; /usr/bin/mc policy set public myminio/iceberg-warehouse; /usr/bin/mc policy set public myminio/olake-data; echo 'MinIO buckets created successfully'; tail -f /dev/null; "

  # ClickHouse Server with Iceberg support
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-server
    ports:
      - "8123:8123" # HTTP interface
      - "19000:9000" # Native interface
      - "19004:9004" # MySQL interface
    volumes:
      - ./clickhouse-config/config.xml:/etc/clickhouse-server/config.d/config.xml
      - ./clickhouse-config/users.xml:/etc/clickhouse-server/users.d/users.xml
      - clickhouse-data:/var/lib/clickhouse
      - clickhouse-logs:/var/log/clickhouse-server
    environment:
      CLICKHOUSE_DB: default
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ""
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    depends_on:
      minio:
        condition: service_healthy
      mysql:
        condition: service_healthy
      iceberg-rest:
        condition: service_healthy
    networks:
      - clickhouse_lakehouse-net
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping" ]
      interval: 30s
      timeout: 5s
      retries: 3

  # ClickHouse Client for easy CLI access
  clickhouse-client:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-client
    depends_on:
      clickhouse:
        condition: service_healthy
    volumes:
      - ./scripts:/scripts
    networks:
      - clickhouse_lakehouse-net
    stdin_open: true
    tty: true
    command: tail -f /dev/null

  # OLake UI - Data Lake Orchestration Platform
  olake-ui:
    image: registry-1.docker.io/olakego/ui:latest
    container_name: olake-ui
    environment:
      CONTAINER_REGISTRY_BASE: registry-1.docker.io
      OLAKE_SECRET_KEY: ""
      PERSISTENT_DIR: ${PWD}/olake-data
    ports:
      - "8000:8000"  # OLake UI web interface
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${PWD}/olake-data:/tmp/olake-config
    networks:
      - clickhouse_lakehouse-net
    dns:
      - 127.0.0.11
      - 8.8.8.8
    extra_hosts:
      - "mysql:172.25.0.4"
    depends_on:
      postgresql:
        condition: service_healthy
      temporal:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 8000"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s

  # OLake UI Signup Initialization
  olake-signup-init:
    image: registry-1.docker.io/curlimages/curl:latest
    container_name: olake-signup-init
    networks:
      - clickhouse_lakehouse-net
    depends_on:
      olake-ui:
        condition: service_healthy
    environment:
      USERNAME: admin
      PASSWORD: password
      EMAIL: admin@example.com
      OLAKE_APP_URL: "http://olake-ui:8000/signup"
    command: >
      sh -c "
        echo 'signup-init: Initializing user setup...'
        JSON_PAYLOAD=$$(printf '{\"username\":\"%s\",\"password\":\"%s\",\"email\":\"%s\"}' \"$${USERNAME}\" \"$${PASSWORD}\" \"$${EMAIL}\")
        echo \"signup-init: Attempting to create user '$${USERNAME}' via $${OLAKE_APP_URL}\"
        HTTP_RESPONSE_CODE=$$(/usr/bin/curl -s -o /dev/stderr -w '%{http_code}' -X POST -H 'Content-Type: application/json' -d \"$${JSON_PAYLOAD}\" \"$${OLAKE_APP_URL}\")
        echo ''
        if ! [ \"$${HTTP_RESPONSE_CODE}\" -eq \"$${HTTP_RESPONSE_CODE}\" ] 2>/dev/null; then
            echo \"signup-init: ERROR - HTTP_RESPONSE_CODE is not a number: '$${HTTP_RESPONSE_CODE}'\"
            exit 1;
        fi
        if [ \"$${HTTP_RESPONSE_CODE}\" -ge 200 ] && [ \"$${HTTP_RESPONSE_CODE}\" -lt 300 ]; then
          echo \"signup-init: User '$${USERNAME}' creation request successful (HTTP $${HTTP_RESPONSE_CODE}).\";
        else
          echo \"signup-init: User '$${USERNAME}' creation request FAILED (HTTP $${HTTP_RESPONSE_CODE}). Server response body above.\";
          exit 1;
        fi
        echo 'signup-init: User setup process complete.';
      "
    restart: "no"

  # OLake Temporal Worker
  olake-temporal-worker:
    image: registry-1.docker.io/olakego/ui-worker:latest
    container_name: olake-temporal-worker
    networks:
      - clickhouse_lakehouse-net
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${PWD}/olake-data:/tmp/olake-config
    environment:
      CONTAINER_REGISTRY_BASE: registry-1.docker.io
      OLAKE_SECRET_KEY: ""
      PERSISTENT_DIR: ${PWD}/olake-data
      OLAKE_CALLBACK_URL: "http://olake-ui:8000/internal/worker/callback"
      DOCKER_NETWORK: ch-demo_clickhouse_lakehouse-net
      OLAKE_DOCKER_NETWORK: ch-demo_clickhouse_lakehouse-net
    dns:
      - 127.0.0.11
      - 8.8.8.8
    extra_hosts:
      - "mysql:172.25.0.4"
    depends_on:
      temporal:
        condition: service_started
      olake-ui:
        condition: service_healthy
    restart: unless-stopped

  # PostgreSQL for Temporal (OLake's workflow orchestration)
  # Note: Service name must be "postgresql" for OLake UI to connect
  postgresql:
    image: registry-1.docker.io/library/postgres:13
    container_name: temporal-postgresql
    environment:
      POSTGRES_USER: temporal
      POSTGRES_PASSWORD: temporal
    networks:
      - clickhouse_lakehouse-net
    volumes:
      - temporal-postgresql-data:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U temporal -h localhost -p 5432"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Temporal Server (workflow orchestration for OLake)
  temporal:
    image: registry-1.docker.io/temporalio/auto-setup:1.22.3
    container_name: temporal
    depends_on:
      postgresql:
        condition: service_healthy
      temporal-elasticsearch:
        condition: service_healthy
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=postgresql
      - ENABLE_ES=true
      - ES_SEEDS=temporal-elasticsearch
      - ES_VERSION=v7
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    networks:
      - clickhouse_lakehouse-net
    restart: unless-stopped

  # Elasticsearch for Temporal (search backend)
  temporal-elasticsearch:
    image: registry-1.docker.io/library/elasticsearch:7.17.10
    container_name: temporal-elasticsearch
    environment:
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=512mb
      - cluster.routing.allocation.disk.watermark.high=256mb
      - cluster.routing.allocation.disk.watermark.flood_stage=128mb
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms256m -Xmx256m
      - xpack.security.enabled=false
    networks:
      - clickhouse_lakehouse-net
    volumes:
      - temporal-elasticsearch-data:/usr/share/elasticsearch/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=5s"]
      interval: 10s
      timeout: 10s
      retries: 5

  # MySQL Client for easy database access
  mysql-client:
    image: mysql:8.0
    container_name: mysql-client
    depends_on:
      mysql:
        condition: service_healthy
    volumes:
      - ./scripts:/scripts
    networks:
      - clickhouse_lakehouse-net
    stdin_open: true
    tty: true
    command: tail -f /dev/null

volumes:
  mysql-data:
  minio-data:
  clickhouse-data:
  clickhouse-logs:
  temporal-postgresql-data:
  temporal-elasticsearch-data:


networks:
  clickhouse_lakehouse-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16
